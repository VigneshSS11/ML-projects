{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-28T13:47:40.441320Z","iopub.execute_input":"2024-06-28T13:47:40.441727Z","iopub.status.idle":"2024-06-28T13:47:40.944386Z","shell.execute_reply.started":"2024-06-28T13:47:40.441696Z","shell.execute_reply":"2024-06-28T13:47:40.943039Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/spam-detection/tensorflow2/tutorials-spam-detection/1/saved_model.pb\n/kaggle/input/spam-detection/tensorflow2/tutorials-spam-detection/1/variables/variables.index\n/kaggle/input/spam-detection/tensorflow2/tutorials-spam-detection/1/variables/variables.data-00000-of-00001\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-28T10:21:57.047528Z","iopub.execute_input":"2024-06-28T10:21:57.048459Z","iopub.status.idle":"2024-06-28T10:21:57.526034Z","shell.execute_reply.started":"2024-06-28T10:21:57.048398Z","shell.execute_reply":"2024-06-28T10:21:57.524058Z"}}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:47:40.947093Z","iopub.execute_input":"2024-06-28T13:47:40.947714Z","iopub.status.idle":"2024-06-28T13:47:41.807872Z","shell.execute_reply.started":"2024-06-28T13:47:40.947670Z","shell.execute_reply":"2024-06-28T13:47:41.806718Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pip install ucimlrepo","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:47:41.809504Z","iopub.execute_input":"2024-06-28T13:47:41.809872Z","iopub.status.idle":"2024-06-28T13:47:59.004520Z","shell.execute_reply.started":"2024-06-28T13:47:41.809839Z","shell.execute_reply":"2024-06-28T13:47:59.002879Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting ucimlrepo\n  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: pandas>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ucimlrepo) (2.2.2)\nRequirement already satisfied: certifi>=2020.12.5 in /opt/conda/lib/python3.10/site-packages (from ucimlrepo) (2024.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\nDownloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\nInstalling collected packages: ucimlrepo\nSuccessfully installed ucimlrepo-0.0.7\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from ucimlrepo import fetch_ucirepo \n  \n# fetch dataset \nspambase = fetch_ucirepo(id=94) \n  \n# data (as pandas dataframes) \nX = spambase.data.features \n#y = spambase.data.targets \ny = spambase.data.targets.values.ravel()  # Flatten the target array\n\n# metadata \nprint(spambase.metadata) \n  \n# variable information \nprint(spambase.variables) \n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:47:59.006478Z","iopub.execute_input":"2024-06-28T13:47:59.006898Z","iopub.status.idle":"2024-06-28T13:48:00.742438Z","shell.execute_reply.started":"2024-06-28T13:47:59.006859Z","shell.execute_reply":"2024-06-28T13:48:00.741095Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n                          name     role        type demographic  \\\n0               word_freq_make  Feature  Continuous        None   \n1            word_freq_address  Feature  Continuous        None   \n2                word_freq_all  Feature  Continuous        None   \n3                 word_freq_3d  Feature  Continuous        None   \n4                word_freq_our  Feature  Continuous        None   \n5               word_freq_over  Feature  Continuous        None   \n6             word_freq_remove  Feature  Continuous        None   \n7           word_freq_internet  Feature  Continuous        None   \n8              word_freq_order  Feature  Continuous        None   \n9               word_freq_mail  Feature  Continuous        None   \n10           word_freq_receive  Feature  Continuous        None   \n11              word_freq_will  Feature  Continuous        None   \n12            word_freq_people  Feature  Continuous        None   \n13            word_freq_report  Feature  Continuous        None   \n14         word_freq_addresses  Feature  Continuous        None   \n15              word_freq_free  Feature  Continuous        None   \n16          word_freq_business  Feature  Continuous        None   \n17             word_freq_email  Feature  Continuous        None   \n18               word_freq_you  Feature  Continuous        None   \n19            word_freq_credit  Feature  Continuous        None   \n20              word_freq_your  Feature  Continuous        None   \n21              word_freq_font  Feature  Continuous        None   \n22               word_freq_000  Feature  Continuous        None   \n23             word_freq_money  Feature  Continuous        None   \n24                word_freq_hp  Feature  Continuous        None   \n25               word_freq_hpl  Feature  Continuous        None   \n26            word_freq_george  Feature  Continuous        None   \n27               word_freq_650  Feature  Continuous        None   \n28               word_freq_lab  Feature  Continuous        None   \n29              word_freq_labs  Feature  Continuous        None   \n30            word_freq_telnet  Feature  Continuous        None   \n31               word_freq_857  Feature  Continuous        None   \n32              word_freq_data  Feature  Continuous        None   \n33               word_freq_415  Feature  Continuous        None   \n34                word_freq_85  Feature  Continuous        None   \n35        word_freq_technology  Feature  Continuous        None   \n36              word_freq_1999  Feature  Continuous        None   \n37             word_freq_parts  Feature  Continuous        None   \n38                word_freq_pm  Feature  Continuous        None   \n39            word_freq_direct  Feature  Continuous        None   \n40                word_freq_cs  Feature  Continuous        None   \n41           word_freq_meeting  Feature  Continuous        None   \n42          word_freq_original  Feature  Continuous        None   \n43           word_freq_project  Feature  Continuous        None   \n44                word_freq_re  Feature  Continuous        None   \n45               word_freq_edu  Feature  Continuous        None   \n46             word_freq_table  Feature  Continuous        None   \n47        word_freq_conference  Feature  Continuous        None   \n48                 char_freq_;  Feature  Continuous        None   \n49                 char_freq_(  Feature  Continuous        None   \n50                 char_freq_[  Feature  Continuous        None   \n51                 char_freq_!  Feature  Continuous        None   \n52                 char_freq_$  Feature  Continuous        None   \n53                 char_freq_#  Feature  Continuous        None   \n54  capital_run_length_average  Feature  Continuous        None   \n55  capital_run_length_longest  Feature  Continuous        None   \n56    capital_run_length_total  Feature  Continuous        None   \n57                       Class   Target      Binary        None   \n\n                 description units missing_values  \n0                       None  None             no  \n1                       None  None             no  \n2                       None  None             no  \n3                       None  None             no  \n4                       None  None             no  \n5                       None  None             no  \n6                       None  None             no  \n7                       None  None             no  \n8                       None  None             no  \n9                       None  None             no  \n10                      None  None             no  \n11                      None  None             no  \n12                      None  None             no  \n13                      None  None             no  \n14                      None  None             no  \n15                      None  None             no  \n16                      None  None             no  \n17                      None  None             no  \n18                      None  None             no  \n19                      None  None             no  \n20                      None  None             no  \n21                      None  None             no  \n22                      None  None             no  \n23                      None  None             no  \n24                      None  None             no  \n25                      None  None             no  \n26                      None  None             no  \n27                      None  None             no  \n28                      None  None             no  \n29                      None  None             no  \n30                      None  None             no  \n31                      None  None             no  \n32                      None  None             no  \n33                      None  None             no  \n34                      None  None             no  \n35                      None  None             no  \n36                      None  None             no  \n37                      None  None             no  \n38                      None  None             no  \n39                      None  None             no  \n40                      None  None             no  \n41                      None  None             no  \n42                      None  None             no  \n43                      None  None             no  \n44                      None  None             no  \n45                      None  None             no  \n46                      None  None             no  \n47                      None  None             no  \n48                      None  None             no  \n49                      None  None             no  \n50                      None  None             no  \n51                      None  None             no  \n52                      None  None             no  \n53                      None  None             no  \n54                      None  None             no  \n55                      None  None             no  \n56                      None  None             no  \n57  spam (1) or not spam (0)  None             no  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Print first 5 rows of the dataframe\nprint(\"First 5 rows of the dataset:\")\nprint(X.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:48:00.746695Z","iopub.execute_input":"2024-06-28T13:48:00.747116Z","iopub.status.idle":"2024-06-28T13:48:00.768128Z","shell.execute_reply.started":"2024-06-28T13:48:00.747082Z","shell.execute_reply":"2024-06-28T13:48:00.766719Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"First 5 rows of the dataset:\n   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.00               0.64           0.64           0.0   \n1            0.21               0.28           0.50           0.0   \n2            0.06               0.00           0.71           0.0   \n3            0.00               0.00           0.00           0.0   \n4            0.00               0.00           0.00           0.0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n3           0.63            0.00              0.31                0.63   \n4           0.63            0.00              0.31                0.63   \n\n   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n0             0.00            0.00  ...                   0.0         0.00   \n1             0.00            0.94  ...                   0.0         0.00   \n2             0.64            0.25  ...                   0.0         0.01   \n3             0.31            0.63  ...                   0.0         0.00   \n4             0.31            0.63  ...                   0.0         0.00   \n\n   char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0        0.000          0.0        0.778        0.000        0.000   \n1        0.132          0.0        0.372        0.180        0.048   \n2        0.143          0.0        0.276        0.184        0.010   \n3        0.137          0.0        0.137        0.000        0.000   \n4        0.135          0.0        0.135        0.000        0.000   \n\n   capital_run_length_average  capital_run_length_longest  \\\n0                       3.756                          61   \n1                       5.114                         101   \n2                       9.821                         485   \n3                       3.537                          40   \n4                       3.537                          40   \n\n   capital_run_length_total  \n0                       278  \n1                      1028  \n2                      2259  \n3                       191  \n4                       191  \n\n[5 rows x 57 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Print columns of the dataframe\nprint(\"Columns in the dataset:\")\nprint(X.columns)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:48:00.769685Z","iopub.execute_input":"2024-06-28T13:48:00.770154Z","iopub.status.idle":"2024-06-28T13:48:00.782543Z","shell.execute_reply.started":"2024-06-28T13:48:00.770077Z","shell.execute_reply":"2024-06-28T13:48:00.781116Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Columns in the dataset:\nIndex(['word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n       'word_freq_our', 'word_freq_over', 'word_freq_remove',\n       'word_freq_internet', 'word_freq_order', 'word_freq_mail',\n       'word_freq_receive', 'word_freq_will', 'word_freq_people',\n       'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n       'word_freq_business', 'word_freq_email', 'word_freq_you',\n       'word_freq_credit', 'word_freq_your', 'word_freq_font', 'word_freq_000',\n       'word_freq_money', 'word_freq_hp', 'word_freq_hpl', 'word_freq_george',\n       'word_freq_650', 'word_freq_lab', 'word_freq_labs', 'word_freq_telnet',\n       'word_freq_857', 'word_freq_data', 'word_freq_415', 'word_freq_85',\n       'word_freq_technology', 'word_freq_1999', 'word_freq_parts',\n       'word_freq_pm', 'word_freq_direct', 'word_freq_cs', 'word_freq_meeting',\n       'word_freq_original', 'word_freq_project', 'word_freq_re',\n       'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n       'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!',\n       'char_freq_$', 'char_freq_#', 'capital_run_length_average',\n       'capital_run_length_longest', 'capital_run_length_total'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X.shape)\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:48:00.783928Z","iopub.execute_input":"2024-06-28T13:48:00.784371Z","iopub.status.idle":"2024-06-28T13:48:00.799598Z","shell.execute_reply.started":"2024-06-28T13:48:00.784337Z","shell.execute_reply":"2024-06-28T13:48:00.797887Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(4601, 57)\n(4601,)\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Split the data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:48:00.801438Z","iopub.execute_input":"2024-06-28T13:48:00.801831Z","iopub.status.idle":"2024-06-28T13:48:00.824411Z","shell.execute_reply.started":"2024-06-28T13:48:00.801798Z","shell.execute_reply":"2024-06-28T13:48:00.822755Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes Classifier\nnb_classifier = GaussianNB()\nnb_classifier.fit(X_train, y_train)\nnb_pred = nb_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:48:00.825686Z","iopub.execute_input":"2024-06-28T13:48:00.826227Z","iopub.status.idle":"2024-06-28T13:48:00.861325Z","shell.execute_reply.started":"2024-06-28T13:48:00.826188Z","shell.execute_reply":"2024-06-28T13:48:00.859910Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Support Vector Machine Classifier\nsvm_classifier = SVC(kernel='linear')\nsvm_classifier.fit(X_train, y_train)\nsvm_pred = svm_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:48:00.863182Z","iopub.execute_input":"2024-06-28T13:48:00.863654Z","iopub.status.idle":"2024-06-28T13:55:55.073665Z","shell.execute_reply.started":"2024-06-28T13:48:00.863610Z","shell.execute_reply":"2024-06-28T13:55:55.072365Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression Classifier\nlr_classifier = LogisticRegression(max_iter=10000)\nlr_classifier.fit(X_train, y_train)\nlr_pred = lr_classifier.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:55:55.075623Z","iopub.execute_input":"2024-06-28T13:55:55.076001Z","iopub.status.idle":"2024-06-28T13:55:56.867481Z","shell.execute_reply.started":"2024-06-28T13:55:55.075968Z","shell.execute_reply":"2024-06-28T13:55:56.865771Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Evaluate the models\ndef evaluate_model(name, y_test, y_pred):\n    print(f\"Evaluation for {name}:\")\n    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n    print(\"\\n\")\n\nevaluate_model(\"Naive Bayes\", y_test, nb_pred)\nevaluate_model(\"SVM\", y_test, svm_pred)\nevaluate_model(\"Logistic Regression\", y_test, lr_pred)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:55:56.870000Z","iopub.execute_input":"2024-06-28T13:55:56.871201Z","iopub.status.idle":"2024-06-28T13:55:56.951798Z","shell.execute_reply.started":"2024-06-28T13:55:56.871131Z","shell.execute_reply":"2024-06-28T13:55:56.950244Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Evaluation for Naive Bayes:\nAccuracy: 0.8208469055374593\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.73      0.82       531\n           1       0.72      0.95      0.82       390\n\n    accuracy                           0.82       921\n   macro avg       0.83      0.84      0.82       921\nweighted avg       0.85      0.82      0.82       921\n\nConfusion Matrix:\n [[387 144]\n [ 21 369]]\n\n\nEvaluation for SVM:\nAccuracy: 0.9229098805646037\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.95      0.93       531\n           1       0.93      0.88      0.91       390\n\n    accuracy                           0.92       921\n   macro avg       0.92      0.92      0.92       921\nweighted avg       0.92      0.92      0.92       921\n\nConfusion Matrix:\n [[506  25]\n [ 46 344]]\n\n\nEvaluation for Logistic Regression:\nAccuracy: 0.9229098805646037\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.95      0.93       531\n           1       0.93      0.88      0.91       390\n\n    accuracy                           0.92       921\n   macro avg       0.92      0.92      0.92       921\nweighted avg       0.92      0.92      0.92       921\n\nConfusion Matrix:\n [[506  25]\n [ 46 344]]\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:55:56.954441Z","iopub.execute_input":"2024-06-28T13:55:56.955645Z","iopub.status.idle":"2024-06-28T13:55:57.363230Z","shell.execute_reply.started":"2024-06-28T13:55:56.955577Z","shell.execute_reply":"2024-06-28T13:55:57.361964Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Random Forest Classifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_classifier.fit(X_train, y_train)\nrf_pred = rf_classifier.predict(X_test)\nevaluate_model(\"Random Forest\", y_test, rf_pred)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T13:55:57.367051Z","iopub.execute_input":"2024-06-28T13:55:57.367464Z","iopub.status.idle":"2024-06-28T13:55:58.262986Z","shell.execute_reply.started":"2024-06-28T13:55:57.367430Z","shell.execute_reply":"2024-06-28T13:55:58.261714Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Evaluation for Random Forest:\nAccuracy: 0.9554831704668838\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.94      0.98      0.96       531\n           1       0.98      0.92      0.95       390\n\n    accuracy                           0.96       921\n   macro avg       0.96      0.95      0.95       921\nweighted avg       0.96      0.96      0.96       921\n\nConfusion Matrix:\n [[522   9]\n [ 32 358]]\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier","metadata":{"execution":{"iopub.status.busy":"2024-06-28T14:35:28.539463Z","iopub.execute_input":"2024-06-28T14:35:28.539909Z","iopub.status.idle":"2024-06-28T14:35:28.553813Z","shell.execute_reply.started":"2024-06-28T14:35:28.539874Z","shell.execute_reply":"2024-06-28T14:35:28.552621Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Neural Network (MLPClassifier)\nmlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\nmlp_classifier.fit(X_train, y_train)\nmlp_pred = mlp_classifier.predict(X_test)\nevaluate_model(\"Neural Network\", y_test, mlp_pred)","metadata":{"execution":{"iopub.status.busy":"2024-06-28T14:36:14.260771Z","iopub.execute_input":"2024-06-28T14:36:14.261763Z","iopub.status.idle":"2024-06-28T14:36:18.598805Z","shell.execute_reply.started":"2024-06-28T14:36:14.261727Z","shell.execute_reply":"2024-06-28T14:36:18.596819Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Evaluation for Neural Network:\nAccuracy: 0.9402823018458197\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95       531\n           1       0.94      0.91      0.93       390\n\n    accuracy                           0.94       921\n   macro avg       0.94      0.94      0.94       921\nweighted avg       0.94      0.94      0.94       921\n\nConfusion Matrix:\n [[510  21]\n [ 34 356]]\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#The model with least with high F1 score(Precsion and recall hand in hand) is the best model, So in our SVM, Naive Bayes,\n#Logistic regression, Random forest and NN the Random forest is the best model","metadata":{},"execution_count":null,"outputs":[]}]}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24c01f22987a48b095c1fccdc9eefeeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_088b84d7354341b7ba6798c3b6d59358",
              "IPY_MODEL_2c23efa9ba9c4d0c845746a9d721a870",
              "IPY_MODEL_beb976e9894e4073b5b0493419261645"
            ],
            "layout": "IPY_MODEL_5ce94dc0351646129117a825159f6e0e"
          }
        },
        "088b84d7354341b7ba6798c3b6d59358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_253694b1ecd34658a250484e8f223db0",
            "placeholder": "​",
            "style": "IPY_MODEL_a80e4f382d5847fc963c2edf979beeed",
            "value": "config.json: 100%"
          }
        },
        "2c23efa9ba9c4d0c845746a9d721a870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0705731f49d64188ac68f0117f28abed",
            "max": 106,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2a4736e278f44eb8e98e1dfa3e7238d",
            "value": 106
          }
        },
        "beb976e9894e4073b5b0493419261645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92ea52bf79974c9b89b044afde936ded",
            "placeholder": "​",
            "style": "IPY_MODEL_c72893d53949473b99c3507f6add255e",
            "value": " 106/106 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "5ce94dc0351646129117a825159f6e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253694b1ecd34658a250484e8f223db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80e4f382d5847fc963c2edf979beeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0705731f49d64188ac68f0117f28abed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a4736e278f44eb8e98e1dfa3e7238d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92ea52bf79974c9b89b044afde936ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72893d53949473b99c3507f6add255e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f682a325d7149518a64178e013bc648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7c6363e7d4e49599a8d208d73350437",
              "IPY_MODEL_c3e119d022b84160be56526f7b959b4e",
              "IPY_MODEL_96fc8bf081c34fd2a744143e212adfad"
            ],
            "layout": "IPY_MODEL_c1057ad4df5f446fbb020bf96b6ae13a"
          }
        },
        "e7c6363e7d4e49599a8d208d73350437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7393bc507fc046d3ad5c3ad4fbc69f5e",
            "placeholder": "​",
            "style": "IPY_MODEL_b77fd31cddaa49e9b0aa94ac3142d299",
            "value": "model.safetensors: 100%"
          }
        },
        "c3e119d022b84160be56526f7b959b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf18b2e967040ef8fd6f5ffef866acd",
            "max": 77934080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c228f28dd26742ef85f317ec2827d6f2",
            "value": 77934080
          }
        },
        "96fc8bf081c34fd2a744143e212adfad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0d1559ed20e4486a25226981ff125ba",
            "placeholder": "​",
            "style": "IPY_MODEL_eacc4fae8ae84228a129189abbc4ea46",
            "value": " 77.9M/77.9M [00:01&lt;00:00, 92.0MB/s]"
          }
        },
        "c1057ad4df5f446fbb020bf96b6ae13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7393bc507fc046d3ad5c3ad4fbc69f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77fd31cddaa49e9b0aa94ac3142d299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bf18b2e967040ef8fd6f5ffef866acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c228f28dd26742ef85f317ec2827d6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0d1559ed20e4486a25226981ff125ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacc4fae8ae84228a129189abbc4ea46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Team Name: Pathfinder \\\n",
        "Team Member: Vignesh S S\\\n",
        "Problem Statememnt: AI-Based Computer Vision for Healthcare Hackathon\\\n",
        "Dataset Link: https://drive.google.com/drive/u/1/folders/1UVvAea975DxWIYFSULqmqVMKLquBOs1Y \\\n",
        "\n",
        "**Image quality analyser based on outputs of Segmentation and Landmark prediction made**\n",
        "\n"
      ],
      "metadata": {
        "id": "8-67OL-5CvOK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3aYTy6NeCt-y",
        "outputId": "02e6934f-1abd-4bcb-976c-fab01c28bf58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.3)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.10)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.1)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.35.3)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (11.3.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.6.2)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (1.0.20)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.5)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, segmentation-models-pytorch\n",
            "Successfully installed lightning-utilities-0.15.2 segmentation-models-pytorch-0.5.0 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Install all required libraries\n",
        "!pip install -U torchmetrics albumentations segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount your Google Drive at /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "# IMPORTANT: Change this to the exact name of your zip file in Google Drive\n",
        "ZIP_FILE_NAME = \"/Hackathon_Dataset_20251025T071740Z.zip\"\n",
        "ZIP_PATH_ON_DRIVE = f\"/content/{ZIP_FILE_NAME}\"\n",
        "UNZIP_DESTINATION = \"/content/\"  # Unzips to the fast local /content/ disk\n",
        "\n",
        "# --- Unzip Logic ---\n",
        "if os.path.exists(ZIP_PATH_ON_DRIVE):\n",
        "    print(f\"Found zip file at: {ZIP_PATH_ON_DRIVE}\")\n",
        "    print(\"Unzipping to local disk... This may take a minute.\")\n",
        "    # -q (quiet) suppresses the long list of all 200+ files\n",
        "    !unzip -q \"{ZIP_PATH_ON_DRIVE}\" -d \"{UNZIP_DESTINATION}\"\n",
        "    print(\"Unzipping complete!\")\n",
        "\n",
        "    # Verify the expected folder is now present\n",
        "    print(\"Contents of /content/ (your unzipped data):\")\n",
        "    !ls \"/content/\"\n",
        "else:\n",
        "    print(f\"ERROR: Zip file not found at: {ZIP_PATH_ON_DRIVE}\")\n",
        "    print(\"Please check the file name and its location in your Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUVzskP4Dc4I",
        "outputId": "bf406c5d-69dd-45af-9723-ffa5adbad28e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found zip file at: /content//Hackathon_Dataset_20251025T071740Z.zip\n",
            "Unzipping to local disk... This may take a minute.\n",
            "Unzipping complete!\n",
            "Contents of /content/ (your unzipped data):\n",
            " drive\t\t      Hackathon_Dataset_20251025T071740Z.zip\n",
            "'Hackathon Dataset'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The Complete IQA + AI Pipeline\n",
        "\n",
        "# --- 1. Imports ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2  # OpenCV\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import segmentation_models_pytorch as smp\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "McEVxj-nDqDY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow # To display images in Colab\n",
        "from IPython.display import HTML # To embed videos in Colab"
      ],
      "metadata": {
        "id": "mfPgmnv8JeIF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_VIDEO_PATH = os.path.join(\n",
        "    DRIVE_PATH, \"hackathon_submission/Results/Video1_output.mp4\"\n",
        ")\n",
        "os.makedirs(os.path.dirname(SAVE_VIDEO_PATH), exist_ok=True)"
      ],
      "metadata": {
        "id": "uPcNoCw9JjSg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = \"/content/drive/My Drive/\"\n",
        "# This is the path to the unzipped folder on the *local* Colab disk\n",
        "LOCAL_DATA_PATH = \"/content/Hackathon Dataset/\"\n",
        "TARGET_IMG_SIZE = (384, 384)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- Define Model Save Paths (on Google Drive) ---\n",
        "SEG_MODEL_PATH = os.path.join(\n",
        "    DRIVE_PATH,\n",
        "    \"hackathon_submission/task_1_segmentation/Model Weights/best_model_hypothesis_1.pth\"\n",
        ")\n",
        "LAND_MODEL_PATH = os.path.join(\n",
        "    DRIVE_PATH,\n",
        "    \"hackathon_submission/task_1_landmark/Model Weights/best_model_hypothesis_1.pth\"\n",
        ")\n",
        "\n",
        "# --- Define Output Path (on Google Drive) ---\n",
        "RESULTS_SAVE_DIR = os.path.join(\n",
        "    DRIVE_PATH, \"hackathon_submission/Results/Video_1_Frames/\"\n",
        ")\n",
        "os.makedirs(RESULTS_SAVE_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "abx-6fiQD9Dn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Re-define Model Architectures (to load weights) ---\n",
        "\n",
        "# Model 1: Segmentation\n",
        "# --- Hyperparameters ---\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_CLASSES = 3\n",
        "NUM_EPOCHS = 40  # <--- CHANGED: Increased from 25 to 40\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# --- Model (U-Net) ---\n",
        "# --- !!! THIS IS THE KEY CHANGE !!! ---\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b4\",  # <--- CHANGED: Swapped for a powerful encoder\n",
        "    encoder_weights=\"imagenet\",   # We still use pre-trained weights\n",
        "    in_channels=1,\n",
        "    classes=NUM_CLASSES,\n",
        ").to(DEVICE)\n",
        "\n",
        "# Model 2: Landmark\n",
        "class LandmarkUNet(nn.Module):\n",
        "    def __init__(self, n_outputs=4):\n",
        "        super().__init__()\n",
        "        self.base_model = smp.Unet(\n",
        "            encoder_name=\"resnet34\", encoder_weights=None,\n",
        "            in_channels=1, classes=3\n",
        "        )\n",
        "        self.encoder = self.base_model.encoder\n",
        "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(512, 128), nn.ReLU(), nn.Linear(128, n_outputs)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        x = features[-1]\n",
        "        x = self.pooling(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "land_model = LandmarkUNet(n_outputs=4).to(DEVICE)\n",
        "\n",
        "# --- 4. Load Saved Model Weights ---\n",
        "print(f\"Loading models from {DRIVE_PATH}...\")\n",
        "try:\n",
        "    seg_model.load_state_dict(torch.load(SEG_MODEL_PATH, map_location=DEVICE))\n",
        "    land_model.load_state_dict(torch.load(LAND_MODEL_PATH, map_location=DEVICE))\n",
        "    seg_model.eval()\n",
        "    land_model.eval()\n",
        "    print(\"Models loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"--- FATAL ERROR: Could not load models. Check paths. {e} ---\")\n",
        "    raise e\n",
        "\n",
        "# --- 5. Helper Functions for Preprocessing & IQA ---\n",
        "\n",
        "def letterbox_frame(image_gray, target_size=(384, 384)):\n",
        "    h, w = image_gray.shape[:2]\n",
        "    scale = min(target_size[0] / h, target_size[1] / w)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "\n",
        "    resized_image = cv2.resize(\n",
        "        image_gray, (new_w, new_h), interpolation=cv2.INTER_LINEAR\n",
        "    )\n",
        "\n",
        "    top = (target_size[0] - new_h) // 2\n",
        "    left = (target_size[1] - new_w) // 2\n",
        "    bottom = target_size[0] - new_h - top\n",
        "    right = target_size[1] - new_w - left\n",
        "\n",
        "    padded_image_gray = cv2.copyMakeBorder(\n",
        "        resized_image, top, bottom, left, right,\n",
        "        borderType=cv2.BORDER_CONSTANT, value=0\n",
        "    )\n",
        "\n",
        "    scale_info = (scale, left, top)\n",
        "    tensor_image = torch.from_numpy(padded_image_gray).float().unsqueeze(0).unsqueeze(0)\n",
        "    tensor_image = (tensor_image / 255.0).to(DEVICE)\n",
        "\n",
        "    return tensor_image, padded_image_gray, scale_info\n",
        "\n",
        "def get_circularity(mask):\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours: return 0.0\n",
        "    contour = max(contours, key=cv2.contourArea)\n",
        "    area = cv2.contourArea(contour)\n",
        "    perimeter = cv2.arcLength(contour, True)\n",
        "    if perimeter == 0: return 0.0\n",
        "    return (4 * np.pi * area) / (perimeter**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "24c01f22987a48b095c1fccdc9eefeeb",
            "088b84d7354341b7ba6798c3b6d59358",
            "2c23efa9ba9c4d0c845746a9d721a870",
            "beb976e9894e4073b5b0493419261645",
            "5ce94dc0351646129117a825159f6e0e",
            "253694b1ecd34658a250484e8f223db0",
            "a80e4f382d5847fc963c2edf979beeed",
            "0705731f49d64188ac68f0117f28abed",
            "d2a4736e278f44eb8e98e1dfa3e7238d",
            "92ea52bf79974c9b89b044afde936ded",
            "c72893d53949473b99c3507f6add255e",
            "8f682a325d7149518a64178e013bc648",
            "e7c6363e7d4e49599a8d208d73350437",
            "c3e119d022b84160be56526f7b959b4e",
            "96fc8bf081c34fd2a744143e212adfad",
            "c1057ad4df5f446fbb020bf96b6ae13a",
            "7393bc507fc046d3ad5c3ad4fbc69f5e",
            "b77fd31cddaa49e9b0aa94ac3142d299",
            "5bf18b2e967040ef8fd6f5ffef866acd",
            "c228f28dd26742ef85f317ec2827d6f2",
            "a0d1559ed20e4486a25226981ff125ba",
            "eacc4fae8ae84228a129189abbc4ea46"
          ]
        },
        "id": "N0h486JwEi2q",
        "outputId": "31a64381-a76b-44dc-a60f-b0821cc8d8ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24c01f22987a48b095c1fccdc9eefeeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f682a325d7149518a64178e013bc648"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models from /content/drive/My Drive/...\n",
            "Models loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. (UPGRADED) IQA Function with Debugging ---\n",
        "\n",
        "# --- !!! TUNE THESE THRESHOLDS !!! ---\n",
        "# Based on the debug output, you may need to change these.\n",
        "# I've lowered them to be safer.\n",
        "IQA_DEBUG_MODE = True       # SET TO TRUE to see why it's failing\n",
        "MIN_CARDIAC_AREA = 1000     # Lowered\n",
        "MIN_THORAX_AREA = 5000      # Lowered\n",
        "MAX_CHAMBER_DARKNESS = 80   # Increased (allows brighter)\n",
        "MIN_THORAX_CIRCULARITY = 0.6 # Lowered (allows less circular)\n",
        "\n",
        "def run_iqa(frame_tensor, original_padded_frame, seg_model):\n",
        "    with torch.no_grad():\n",
        "        mask_logits = seg_model(frame_tensor)\n",
        "        mask_pred = torch.argmax(mask_logits, dim=1).squeeze().cpu().numpy().astype(np.uint8)\n",
        "\n",
        "    # --- 1. Size Check ---\n",
        "    cardiac_area = np.sum(mask_pred == 1)\n",
        "    thorax_area = np.sum(mask_pred == 2)\n",
        "\n",
        "    # --- 2. Darkness Check ---\n",
        "    cardiac_pixels = original_padded_frame[mask_pred == 1]\n",
        "    avg_darkness = np.mean(cardiac_pixels) if len(cardiac_pixels) > 0 else 999\n",
        "\n",
        "    # --- 3. Circularity Check ---\n",
        "    thorax_mask = np.where(mask_pred == 2, 255, 0).astype(np.uint8)\n",
        "    circularity = get_circularity(thorax_mask)\n",
        "\n",
        "    # --- Debug Print ---\n",
        "    if IQA_DEBUG_MODE:\n",
        "        debug_msg = (\n",
        "            f\"  [IQA Values: \"\n",
        "            f\"CardiacArea={cardiac_area} (Min={MIN_CARDIAC_AREA}), \"\n",
        "            f\"ThoraxArea={thorax_area} (Min={MIN_THORAX_AREA}), \"\n",
        "            f\"Darkness={avg_darkness:.1f} (Max={MAX_CHAMBER_DARKNESS}), \"\n",
        "            f\"Circularity={circularity:.2f} (Min={MIN_THORAX_CIRCULARITY})]\"\n",
        "        )\n",
        "\n",
        "    # --- Check Rules ---\n",
        "    if (cardiac_area < MIN_CARDIAC_AREA) or (thorax_area < MIN_THORAX_AREA):\n",
        "        return f\"FAIL: Area too small {debug_msg if IQA_DEBUG_MODE else ''}\"\n",
        "    if avg_darkness > MAX_CHAMBER_DARKNESS:\n",
        "        return f\"FAIL: Chambers not dark {debug_msg if IQA_DEBUG_MODE else ''}\"\n",
        "    if circularity < MIN_THORAX_CIRCULARITY:\n",
        "        return f\"FAIL: Thorax not circular {debug_msg if IQA_DEBUG_MODE else ''}\"\n",
        "\n",
        "    return \"PASS\" # All checks passed"
      ],
      "metadata": {
        "id": "RzvvXEDpESLN"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. The Main AI Pipeline (Now saving to VIDEO) ---\n",
        "\n",
        "VIDEO_PATH = os.path.join(LOCAL_DATA_PATH, \"Videos/Video1.mp4\")\n",
        "print(f\"\\n--- Starting AI Pipeline for {VIDEO_PATH} ---\")\n",
        "\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    print(f\"ERROR: Could not open video file: {VIDEO_PATH}\")\n",
        "else:\n",
        "    # Get video properties for VideoWriter\n",
        "    frame_width = int(TARGET_IMG_SIZE[1])\n",
        "    frame_height = int(TARGET_IMG_SIZE[0])\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # --- NEW: Setup VideoWriter ---\n",
        "    # We will write our output video to this object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out_video = cv2.VideoWriter(\n",
        "        SAVE_VIDEO_PATH, fourcc, fps, (frame_width, frame_height)\n",
        "    )\n",
        "\n",
        "    frame_count = 0\n",
        "    saved_frame_count = 0\n",
        "    first_pass_shown = False\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        frame_tensor, frame_padded_gray, scale_info = letterbox_frame(frame_gray)\n",
        "\n",
        "        # Create a 3-channel (color) image for drawing\n",
        "        frame_to_draw = cv2.cvtColor(frame_padded_gray, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "        quality_status = run_iqa(frame_tensor, frame_padded_gray, seg_model)\n",
        "\n",
        "        if quality_status == \"PASS\":\n",
        "            with torch.no_grad():\n",
        "                norm_landmarks = land_model(frame_tensor)\n",
        "\n",
        "            scale, pad_left, pad_top = scale_info\n",
        "            landmarks = norm_landmarks.cpu().numpy().squeeze()\n",
        "            landmarks = (landmarks * TARGET_IMG_SIZE[1])\n",
        "\n",
        "            center_y = TARGET_IMG_SIZE[0] // 2\n",
        "            for x_coord in landmarks:\n",
        "                cv2.circle(\n",
        "                    img=frame_to_draw, center=(int(x_coord), center_y),\n",
        "                    radius=5, color=(0, 255, 0), thickness=-1\n",
        "                )\n",
        "\n",
        "            saved_frame_count += 1\n",
        "\n",
        "            # --- NEW: Display first good frame in Colab ---\n",
        "            if not first_pass_shown:\n",
        "                print(\"\\n--- FIRST FRAME THAT PASSED IQA ---\")\n",
        "                cv2_imshow(frame_to_draw)\n",
        "                print(\"-----------------------------------\")\n",
        "                first_pass_shown = True\n",
        "\n",
        "        # --- NEW: Write frame to video ---\n",
        "        # We write every frame to the video.\n",
        "        # If it's a \"FAIL\" frame, it will be the original padded frame.\n",
        "        # If it's a \"PASS\" frame, it will have the green dots.\n",
        "        # This shows the IQA working (dots will appear and disappear).\n",
        "        out_video.write(frame_to_draw)\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % 10 == 0: # Print status every 10 frames\n",
        "            print(f\"Frame {frame_count}: {quality_status}\")\n",
        "\n",
        "    cap.release()\n",
        "    out_video.release() # --- NEW: Finalize the video\n",
        "    print(\"--- Pipeline Finished ---\")\n",
        "    print(f\"Processed {frame_count} total frames.\")\n",
        "    print(f\"Saved {saved_frame_count} high-quality frames to video.\")\n",
        "    print(f\"Output video saved to: {SAVE_VIDEO_PATH}\")\n",
        "\n",
        "# --- 8. NEW: Display Final Video in Colab ---\n",
        "print(\"\\n--- Embedding Final Video ---\")\n",
        "\n",
        "# Create a relative path for the HTML player\n",
        "# We need to strip \"/content/drive/My Drive/\" and add \"drive/My Drive/\"\n",
        "relative_video_path = SAVE_VIDEO_PATH.replace(\"/content/drive/My Drive/\", \"drive/My Drive/\")\n",
        "\n",
        "HTML(f\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"{relative_video_path}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "3hMnp8e4Eq8M",
        "outputId": "9fb85ca2-4096-4fc3-8931-4d41553a6931"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting AI Pipeline for /content/Hackathon Dataset/Videos/Video1.mp4 ---\n",
            "Frame 10: FAIL: Area too small   [IQA Values: CardiacArea=0 (Min=1000), ThoraxArea=4149 (Min=5000), Darkness=999.0 (Max=80), Circularity=0.87 (Min=0.6)]\n",
            "Frame 20: FAIL: Area too small   [IQA Values: CardiacArea=0 (Min=1000), ThoraxArea=3787 (Min=5000), Darkness=999.0 (Max=80), Circularity=0.87 (Min=0.6)]\n",
            "Frame 30: FAIL: Area too small   [IQA Values: CardiacArea=10 (Min=1000), ThoraxArea=4171 (Min=5000), Darkness=31.2 (Max=80), Circularity=0.86 (Min=0.6)]\n",
            "Frame 40: FAIL: Area too small   [IQA Values: CardiacArea=57 (Min=1000), ThoraxArea=3896 (Min=5000), Darkness=34.1 (Max=80), Circularity=0.88 (Min=0.6)]\n",
            "Frame 50: FAIL: Area too small   [IQA Values: CardiacArea=377 (Min=1000), ThoraxArea=3195 (Min=5000), Darkness=16.6 (Max=80), Circularity=0.85 (Min=0.6)]\n",
            "Frame 60: FAIL: Area too small   [IQA Values: CardiacArea=112 (Min=1000), ThoraxArea=3384 (Min=5000), Darkness=21.5 (Max=80), Circularity=0.86 (Min=0.6)]\n",
            "Frame 70: FAIL: Area too small   [IQA Values: CardiacArea=51 (Min=1000), ThoraxArea=3002 (Min=5000), Darkness=19.8 (Max=80), Circularity=0.86 (Min=0.6)]\n",
            "Frame 80: FAIL: Area too small   [IQA Values: CardiacArea=38 (Min=1000), ThoraxArea=3477 (Min=5000), Darkness=3.3 (Max=80), Circularity=0.87 (Min=0.6)]\n",
            "Frame 90: FAIL: Area too small   [IQA Values: CardiacArea=13 (Min=1000), ThoraxArea=2469 (Min=5000), Darkness=6.5 (Max=80), Circularity=0.82 (Min=0.6)]\n",
            "Frame 100: FAIL: Area too small   [IQA Values: CardiacArea=0 (Min=1000), ThoraxArea=2258 (Min=5000), Darkness=999.0 (Max=80), Circularity=0.86 (Min=0.6)]\n",
            "--- Pipeline Finished ---\n",
            "Processed 107 total frames.\n",
            "Saved 0 high-quality frames to video.\n",
            "Output video saved to: /content/drive/My Drive/hackathon_submission/Results/Video1_output.mp4\n",
            "\n",
            "--- Embedding Final Video ---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "  <source src=\"drive/My Drive/hackathon_submission/Results/Video1_output.mp4\" type=\"video/mp4\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8ARlrMhIjvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}